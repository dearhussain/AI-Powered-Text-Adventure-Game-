# -*- coding: utf-8 -*-
"""AI_Stroytelling_Adventure.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fmVB-X_LhlRcCdptlrymWfIX4YR314xZ

Project Name: **AI Storytelling Adventure**

Project Description:
`This project creates an interactive AI-powered storytelling game using a deep learning model (LSTM) trained on Alice‚Äôs Adventures in Wonderland. The AI predicts and generates the next part of the story based on user input, making the game fun and dynamic.
The model learns how words connect, ensuring smooth and meaningful storytelling. The game is built with Streamlit/Flask, so users can play it online easily.
This project highlights AI, NLP, and Deep Learning, making it a great addition to a data science portfolio.
`

Date: 13/3/2025

# Scraping the Book
"""

import requests
from bs4 import BeautifulSoup

# URL of the book on Project Gutenberg
BOOK_URL = "https://www.gutenberg.org/files/11/11-0.txt"

# function to scrap and clean the text
def scrape_book(url):
    response = requests.get(url)
    response.encoding = "utf-8"  # Ensure correct text encoding

    if response.status_code == 200:
        text = response.text

        # Remove Gutenberg's header and footer
        start_marker = "*** START OF THIS PROJECT GUTENBERG EBOOK ALICE‚ÄôS ADVENTURES ***"
        end_marker = "*** END OF THIS PROJECT GUTENBERG EBOOK ALICE‚ÄôS ADVENTURES ***"

        start_idx = text.find(start_marker) + len(start_marker)
        end_idx = text.find(end_marker)

        if start_idx != -1 and end_idx != -1:
            cleaned_text = text[start_idx:end_idx].strip()
        else:
            cleaned_text = text  # Fallback to full text if markers not found

        # Save to a file
        with open("alice_wonderland.txt", "w", encoding="utf-8") as file:
            file.write(cleaned_text)

        print("‚úÖ Book scraped and saved as 'alice_wonderland.txt'")
    else:
        print("‚ùå Failed to fetch the book. Check the URL.")

# run the function
scrape_book(BOOK_URL)

print("‚úÖ Book Scraping complete! Ready for Text Preprocessing.")

"""# PreProcess The Text"""

# Import some neccessary libraries
import numpy as np
import pandas as pd

import tensorflow
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import re

# load the clean text file in lower case letter
with open("alice_wonderland.txt", "r", encoding="utf-8") as file:
    text = file.read().lower()

# Calculate one third of the text length
# half_length = len(text) // 2

# # Slice the text to keep only the first one third
# text = text[:half_length]

# # because of ram overloading

# Remove punctuation
text = re.sub(r'[^\w\s]', '', text)

# Replace multiple spaces with a single space
text = re.sub(r'\s+', ' ', text)

# Remove numbers (if they are not relevant)
text = re.sub(r'\d+', '', text)

# Strip leading and trailing whitespace
text = text.strip()

# Remove non-ASCII characters (if any)
text = re.sub(r'[^\x00-\x7F]+', '', text)

# Tokenize the text
tokenizer = Tokenizer(num_words=10000)  # Limit vocabulary size
tokenizer.fit_on_texts([text])

tokenizer.word_counts

tokenizer.word_index

total_vocab = len(tokenizer.word_index) + 1
total_vocab

# # Convert words to sequences
# sequences = []
# words = text.split()
# for i in range(1, len(words)):
#     sequence = words[:i+1]  # Create input-output pairs
#     sequences.append(sequence)

# # Convert words to numerical values
# # Handle unknown words by replacing them with a default value (e.g., 0)
# sequences = [[tokenizer.word_index.get(word, 0) for word in seq] for seq in sequences]

# sequences

from tensorflow.keras.preprocessing.sequence import pad_sequences

# Tokenize and create sequences with the tokenizer
sequences = tokenizer.texts_to_sequences([text])[0]

# Define sequence length
seq_length = 50

# Generate input-output pairs
input_sequences = []
output_words = []

for i in range(seq_length, len(sequences)):
    input_seq = sequences[i-seq_length:i]  # Sequence of words as input
    output_word = sequences[i]  # The next word to predict
    input_sequences.append(input_seq)
    output_words.append(output_word)

# Pad sequences to ensure they all have the same length
X = pad_sequences(input_sequences, maxlen=seq_length)

# Convert output words into numpy array
import numpy as np
y = np.array(output_words)

X.shape

y.shape

# Convert y to one-hot encoded format
y = tensorflow.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)

y.shape

print("X shape:", X.shape)
print("y shape:", y.shape)

print("‚úÖ Text preprocessing complete! Ready for LSTM training.")

"""# Building the LSTM Model"""

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense,LSTM,Embedding,Input, Dropout

X.shape[1]

total_vocab + 1

model = Sequential()

model.add(Input(shape=(X.shape[1],)))
model.add(Embedding(input_dim=total_vocab+1,output_dim=50))
model.add(LSTM(64, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(total_vocab,activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

history = model.fit(X,y,epochs=100,batch_size=32,validation_split=0.2)

"""# Model Prediction"""

import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences

def generate_text(seed_text, model, tokenizer, seq_length, num_words=50, words_per_line=10):
    output_text = seed_text
    generated_words = []  # Store words separately for formatting

    for _ in range(num_words):
        # Tokenize and pad the input sequence
        encoded = tokenizer.texts_to_sequences([output_text])[0]
        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')

        # Predict the next word
        predicted_index = np.argmax(model.predict(encoded, verbose=0), axis=-1)[0]

        # Convert index to word
        word = tokenizer.index_word.get(predicted_index, '')  # Default to empty if not found
        if not word:
            break  # Stop if no valid word is found

        generated_words.append(word)
        output_text += ' ' + word

    # Format the output in multiple lines
    formatted_text = ""
    for i in range(0, len(generated_words), words_per_line):
        formatted_text += " ".join(generated_words[i:i+words_per_line]) + "\n"

    return formatted_text.strip()  # Remove trailing newlines

# Get input from the user
seed_text = input("Enter a starting phrase: ")

# Generate and display the output
generated_text = generate_text(seed_text, model, tokenizer, seq_length, num_words=50)

print("\nüìù **Generated Story** üìù\n")
print(generated_text)

# User_Input Example
'''üîπ
Fantasy / Wonderland Style

"Alice stepped through the door and found herself in"
"The white rabbit looked at Alice and said,"
"In the middle of the forest, Alice discovered a"
"The Mad Hatter grinned and whispered,"
"Alice picked up the strange golden key and"

üîπ Mystery / Adventure

"The moment Alice touched the mirror, she felt"
"The Queen of Hearts turned to Alice and shouted,"
"Alice followed the Cheshire Cat through the fog and"
"There was a hidden note on the teacup that said,"
"Alice opened the mysterious book and saw"

'''